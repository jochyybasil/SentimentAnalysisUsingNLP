{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "# Prevent future/deprecation warnings from showing in output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp_utils, nltk, re, string\n",
    "import contractions\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  i hate you so much that i am even disgusted when i see you']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = input(\"Type a situation to know its sentiment\")\n",
    "corpus = [user_input]\n",
    "letters_only = re.sub(r'[^a-zA-Z]', \" \", str(corpus))\n",
    "letters_only=letters_only.lower()\n",
    "token=nltk.sent_tokenize(letters_only)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## contractions are expanded and the letters are converted to lowercase.\n",
    "conm = contractions.CONTRACTION_MAP\n",
    "def contraction_remove(corpus_nda):\n",
    "    for key,value in conm.items():\n",
    "        corpus_nda = re.sub(r\"{}\".format(key),'{}'.format(value),corpus_nda)\n",
    "        \n",
    "    return corpus_nda\n",
    "\n",
    "special = string.punctuation\n",
    "def w_tokenization(corpus_nda):\n",
    "    # convert into lower case\n",
    "    corpus_nda = corpus_nda.lower()\n",
    "    # contraction\n",
    "    corpus_nda = contraction_remove(corpus_nda)\n",
    "    # \n",
    "    tokens = nltk.word_tokenize(corpus_nda) # word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i hate you so much that i am even disgusted when i see you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Alpha numeric characters and decimals are replaced with characters\n",
    "def num_dec_al(word):\n",
    "    if word.isnumeric():\n",
    "        return 'xxxxxx'\n",
    "    elif word.isdecimal():\n",
    "        return 'xxx...'\n",
    "    elif word.isalpha():\n",
    "        return word\n",
    "    else:\n",
    "        return 'xxxaaa'\n",
    "\n",
    "def clean_nda(token):\n",
    "    tokens = nlp_utils.w_tokenization(token)\n",
    "    map_list = list(map(num_dec_al,tokens))\n",
    "    return \" \".join(map_list)\n",
    "\n",
    "corpus_nda = list(map(clean_nda,token))\n",
    "corpus_nda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i hate you so much that i am even disgusted wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  i hate you so much that i am even disgusted wh..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(corpus_nda)\n",
    "df= df.rename(columns={0: 'Text'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i hate you so much that i am even disgusted wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  i hate you so much that i am even disgusted wh..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace('\\d+', '', regex=True, inplace=True)\n",
    "df.replace(',', '', regex=True, inplace=True)\n",
    "df.replace('br', '', regex=True, inplace=True)\n",
    "df.replace('\"', '', regex=True, inplace=True)\n",
    "df.replace(\"'\", '', regex=True, inplace=True)\n",
    "df.replace('?', '', inplace=True)\n",
    "df.replace(\"-\", '', regex=True, inplace=True)\n",
    "df.replace(\"*\", '', inplace=True)\n",
    "df.replace(\"***\", '', inplace=True)\n",
    "df.replace(\"< />\", '', regex=True, inplace=True)\n",
    "df['Text'] = df['Text'].str.strip('[')\n",
    "df['Text'] = df['Text'].str.strip(']')\n",
    "df['Text'] = df['Text'].str.strip(')')\n",
    "df['Text'] = df['Text'].str.strip('(')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(nlp_utils.lemmatization_sentence)\n",
    "Text=df['Text']\n",
    "token = df['Text'].to_numpy()\n",
    "token=nltk.sent_tokenize(str(token))\n",
    "data = np.array(token)\n",
    "#data\n",
    "stop = stopwords.words('english')\n",
    "text = data\n",
    "text_tokens = word_tokenize(str(text))\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stop]\n",
    "#print(tokens_without_sw)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transformation - feature detection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "tfidfFile='C:\\\\Users\\\\user\\\\Desktop\\\\SentimentAnalysisUsingNLP\\\\tfidf_Sentiment_Model.pk1'\n",
    "tfidf = pickle.load(open(tfidfFile, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16215)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fresh = tfidf.transform(df['Text']).toarray()\n",
    "X_fresh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "#prediction using classifier\n",
    "import joblib\n",
    "classifier = joblib.load('LR_Classifier_Sentiment_Model')\n",
    "y_pred = classifier.predict(X_fresh)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "classifier = joblib.load('MNB_Classifier_Sentiment_Model')\n",
    "y_pred = classifier.predict(X_fresh)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1f2b33e866b0bf2409397e5f58ba9cdf170d3b7f64c8f359c79998e2f88ad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
